{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"mask_classificationTL.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JD8eouupTR0Y"},"source":["# Mask Classification\n","\n","This Notebook contains a model is based on VGG19, using transfer learning"]},{"cell_type":"code","metadata":{"id":"oXsrPZgcTR0Y","executionInfo":{"status":"ok","timestamp":1606052146042,"user_tz":-60,"elapsed":1505,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["import os\n","import numpy as np \n","import tensorflow as tf \n","import pandas\n","import random\n","\n","SEED = 1234\n","\n","tf.random.set_seed(SEED)\n","\n","GC = True\n","Gio = False "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Xovy5kLKYVB","executionInfo":{"status":"ok","timestamp":1606052146043,"user_tz":-60,"elapsed":886,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}},"outputId":"3ee2a043-17dd-424d-ed3d-41b09d838bba"},"source":["if GC:\n","    from google.colab import drive\n","    drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zAtdUg21WzzH","executionInfo":{"status":"ok","timestamp":1606052146044,"user_tz":-60,"elapsed":782,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["if Gio:\n","  !unzip '/content/drive/My Drive/MaskDataset/artificial-neural-networks-and-deep-learning-2020.zip'\n","  !ls /content/MaskDataset"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q-qjIbNnTR0Z","executionInfo":{"status":"ok","timestamp":1606052150658,"user_tz":-60,"elapsed":1236,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["# Random Noise\n","def add_noise(img):\n","    '''Add random noise to an image'''\n","    VARIABILITY = 50\n","    deviation = VARIABILITY*random.random()\n","    noise = np.random.normal(0, deviation, img.shape)\n","    img += noise\n","    np.clip(img, 0., 255.)\n","    return img"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3eTrVdmBKYVB"},"source":["### Data Augmentation\n","simple transformation as zoom, flip (horizontal and vertical), rotation and shear.<br>\n","From the dataset, the 75% is used for training set with all the trasformation and 25% for validation set\n"]},{"cell_type":"code","metadata":{"id":"SSEZ_Z8sTR0Z","executionInfo":{"status":"ok","timestamp":1606052152367,"user_tz":-60,"elapsed":1090,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","apply_data_augmentation = True\n","\n","if apply_data_augmentation: #if data augmentation is enabled, create the generator\n","     train_data_gen = ImageDataGenerator(rotation_range=10,\n","                                        zoom_range=0.1,\n","                                        horizontal_flip=True,\n","                                        vertical_flip=True,\n","                                        fill_mode='constant',\n","                                        cval=0,\n","                                        shear_range = 0.2, #added for TL\n","                                        validation_split = 0.25,\n","                                        rescale=1./255)\n","else: #rescale only the image\n","     train_data_gen = ImageDataGenerator(rescale = 1./255, validation_split = 0.25)                                       \n","\n","#rescale only on validation dataset and test dataset\n","valid_data_gen = ImageDataGenerator(rescale = 1./255, validation_split= 0.25)\n","\n","test_data_gen = ImageDataGenerator(rescale = 1./255)\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"CMhCCmGCTR0Z","executionInfo":{"status":"ok","timestamp":1606052156472,"user_tz":-60,"elapsed":2582,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["#width and height of imgaes\n","img_w = 256\n","img_h = 256\n","\n","num_classes = 3\n","\n","classes = [\"NO PERSON\", \"ALL THE PEOPLE\", \"SOMEONE\"]\n","\n","bs = 16 #batch size"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"w2eZdIzpTR0Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606052829446,"user_tz":-60,"elapsed":47716,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}},"outputId":"1ccc52ad-0bbc-442d-87a2-9a2678424a8f"},"source":["from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","#Loading data \n","import json \n","\n","cwd = os.getcwd()\n","#setting dirs\n","\n","if not Gio: # Matte\n","  os.chdir('/content/drive/My Drive/PoliMi/1-ANN_DL/LAB/AN2DL-homeworks')\n","\n","dataset_dir = os.path.join(cwd, \"MaskDataset\")\n","\n","training_dir = os.path.join(dataset_dir, \"training\")\n","validation_dir = training_dir\n","\n","\n","#reading json file\n","with open(os.path.join(dataset_dir,\"train_gt.json\")) as f:\n","  dic = json.load(f)\n","\n","\n","dataframe = pandas.DataFrame(dic.items())\n","\n","dataframe.rename(columns = {0:'filename', 1:'class'}, inplace = True)\n","\n","dataframe[\"class\"] = dataframe[\"class\"].astype(str)\n","\n","#shuffling dataframe\n","dataframe = dataframe.sample(frac = 1) \n","\n","train_gen = train_data_gen.flow_from_dataframe(dataframe,\n","                                               training_dir,\n","                                               batch_size=bs,\n","                                               target_size=(img_h, img_w),\n","                                               class_mode='categorical',\n","                                               color_mode='rgb',\n","                                               subset='training',\n","                                               shuffle=True,\n","                                               seed=SEED)\n","\n","valid_gen = valid_data_gen.flow_from_dataframe(dataframe,\n","                                               training_dir,\n","                                               #directory='full_dataset',\n","                                               batch_size=bs,\n","                                               target_size=(img_h, img_w),\n","                                               class_mode='categorical',\n","                                               color_mode='rgb',\n","                                               subset='validation',\n","                                               shuffle=True,\n","                                               seed=SEED) \n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Found 4211 validated image filenames belonging to 3 classes.\n","Found 1403 validated image filenames belonging to 3 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"njtto-WZTR0a","executionInfo":{"status":"ok","timestamp":1606052896483,"user_tz":-60,"elapsed":833,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["#Creating Dataset objects\n","\n","train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n","\n","train_dataset = train_dataset.repeat()\n","\n","\n","valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n","\n","valid_dataset = valid_dataset.repeat()  \n","\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZdwFGpLqTR0a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606052919050,"user_tz":-60,"elapsed":4734,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}},"outputId":"b00a085a-6987-4e9c-bbd7-821ee928394c"},"source":["# Architecture: Features extraction -> Classifier\n","\n","model = tf.keras.Sequential()\n","\n","\n","vgg = tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n","# Create Model\n","    # ------------\n","\n","finetuning = True\n","\n","if finetuning:\n","    freeze_until = 13 # layer from which we want to fine-tune\n","\n","    for layer in vgg.layers:\n","          layer.trainable = False\n","\n","    for layer in vgg.layers[:freeze_until]:\n","          layer.trainable = True\n","else:\n","      for layer in vgg.layers[:]:\n","        layer.trainable = False\n","    \n","model.add(vgg)\n","\n","# Classifier\n","model.add(tf.keras.layers.Flatten())\n","#Basic Model\n","#model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n","#TL\n","model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n","model.add(tf.keras.layers.Dropout(0.3))\n","model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80142336/80134624 [==============================] - 3s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JCcjXwmRTR0a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606052926320,"user_tz":-60,"elapsed":1224,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}},"outputId":"57322c37-98ea-4f8a-f24e-23182a1eb821"},"source":["# Optimization params\n","# -------------------\n","\n","# Loss\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","\n","# learning rate\n","lr = 5e-5 #basic lr 1e-4\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","# -------------------\n","\n","# Validation metrics\n","# ------------------\n","\n","metrics = ['accuracy']\n","# ------------------\n","\n","# Compile Model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","\n","model.summary()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg19 (Functional)           (None, 8, 8, 512)         20024384  \n","_________________________________________________________________\n","flatten (Flatten)            (None, 32768)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               4194432   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 128)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3)                 387       \n","=================================================================\n","Total params: 24,219,203\n","Trainable params: 7,700,547\n","Non-trainable params: 16,518,656\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kAa2st7pTR0b","executionInfo":{"status":"ok","timestamp":1606052936550,"user_tz":-60,"elapsed":1030,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["from datetime import datetime\n","\n","\n","\n","exps_dir = os.path.join(cwd, 'classification_experiments')\n","if not os.path.exists(exps_dir):\n","    os.makedirs(exps_dir)\n","\n","now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","model_name = 'CNN'\n","\n","exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","if not os.path.exists(exp_dir):\n","    os.makedirs(exp_dir)\n","    \n","callbacks = []\n","\n","# Model checkpoint\n","# ----------------\n","ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","if not os.path.exists(ckpt_dir):\n","    os.makedirs(ckpt_dir)\n","\n","ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n","                                                   save_weights_only=True)  # False to save the model directly\n","callbacks.append(ckpt_callback)\n","\n","# Visualize Learning on Tensorboard\n","# ---------------------------------\n","tb_dir = os.path.join(exp_dir, 'tb_logs')\n","if not os.path.exists(tb_dir):\n","    os.makedirs(tb_dir)\n","    \n","# By default shows losses and metrics for both training and validation\n","tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                             profile_batch=0,\n","                                             histogram_freq=1)  # if 1 shows weights histograms\n","callbacks.append(tb_callback)\n","\n","# Early Stopping\n","# --------------\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,restore_best_weights=True )\n","    callbacks.append(es_callback)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"yhznJTBcTR0b","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7670c85a-9bec-4990-e0fb-a99786df0470"},"source":["model.fit(x=train_dataset,\n","          epochs=30,  #### set repeat in training dataset\n","          steps_per_epoch=len(train_gen),\n","          validation_data=valid_dataset,\n","          validation_steps=len(valid_gen), \n","          callbacks=callbacks)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n"," 14/264 [>.............................] - ETA: 38:53 - loss: 1.2823 - accuracy: 0.3080"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5VArt4RvTR0b"},"source":["#check that is all ok\n","\n","#iterator = iter(valid_dataset)\n","\n","\n","\n","#from PIL import Image\n","\n","#for i in range(10):\n","#    sample, target = next(iterator)\n","#    sample_ = sample[0, ...]\n","\n","#    img = Image.fromarray(np.uint8(np.array(sample_)*255.))\n","#    img = img.resize([img_w,img_h])\n","#    img_array = np.array(img)\n","#    img_array = np.expand_dims(img_array, 0) \n","#    img_array = tf.cast(img_array, tf.float32) / 255.\n","#    prediction = model.predict(img_array)\n","#    img\n","#    print(\"Predicted:\"+classes[np.argmax(prediction)])\n","#    print(\"Original:\" +classes[tf.argmax(target[0], axis=0)])\n","\n","#sample_\n","#class_names[tf.argmax(target[0], axis=0)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJ3fEg8pTR0b"},"source":["# Test Dataset \n","# Useful if you want to see images with predictions  \n","\n","#from PIL import Image\n","#image_filenames = next(os.walk('MaskDataset/test'))[2]\n","\n","#results = {}\n","#for image_name in image_filenames:\n","#   img = Image.open('MaskDataset/test/'+image_name).convert('RGB')\n","#   img = img.resize((img_w,img_h))\n","#   img_array = np.array(img)\n","#   img_array = np.expand_dims(img_array, 0) \n","#   img_array = tf.cast(img_array, tf.float32) / 255.\n","#   prediction = model.predict(img_array)\n","#   img\n","#   classes[np.argmax(prediction)]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GcNfRAnuTR0b"},"source":["#Creating CSV\n","\n","import os\n","from datetime import datetime\n","from PIL import Image\n","\n","def create_csv(results, results_dir='./'):\n","\n","    csv_fname = 'results_'\n","    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n","\n","    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n","\n","        f.write('Id,Category\\n')\n","\n","        for key, value in results.items():\n","            f.write(key + ',' + str(value) + '\\n')\n","\n","\n","image_filenames = next(os.walk('MaskDataset/test'))[2]\n","\n","results = {}\n","for image_name in image_filenames:\n","   img = Image.open('MaskDataset/test/'+image_name).convert('RGB')\n","   img = img.resize((img_w,img_h))\n","   img_array = np.array(img)\n","   img_array = np.expand_dims(img_array, 0) \n","   img_array = tf.cast(img_array, tf.float32) / 255.\n","   prediction = model.predict(img_array)\n","   results[image_name] = np.argmax(prediction)\n","\n","create_csv(results)            "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oIQ7qasmTR0c"},"source":[""],"execution_count":null,"outputs":[]}]}