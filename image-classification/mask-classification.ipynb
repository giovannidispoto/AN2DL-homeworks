{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3.7.9 64-bit ('tf_env': conda)","metadata":{"interpreter":{"hash":"07a1d00ae2162815ae6e2da7ddb78c532f34cdf0562699979b491324286053b0"}}},"colab":{"name":"mask-classification.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yMvFBfzitV3g"},"source":["# Mask Classification\n","\n","This Notebook contains a model trainable from scratch a model based on VGG16"]},{"cell_type":"code","metadata":{"id":"akEljUKUtV3g","executionInfo":{"status":"ok","timestamp":1605711715334,"user_tz":-60,"elapsed":2260,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["import os\n","import numpy as np \n","import tensorflow as tf \n","import pandas\n","\n","SEED = 1234\n","\n","tf.random.set_seed(SEED)\n","\n","cwd = os.getcwd();"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qCmzt0YHynxL","executionInfo":{"status":"ok","timestamp":1605711742524,"user_tz":-60,"elapsed":29414,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}},"outputId":"541fdceb-ae74-4907-cc66-e095b13f7dda"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"THgyCBeLtV3g","executionInfo":{"status":"ok","timestamp":1605711742529,"user_tz":-60,"elapsed":29394,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","\n","apply_data_augmentation = True\n","\n","if apply_data_augmentation: #if data augmentation is enabled, create the generator\n","     train_data_gen = ImageDataGenerator(rotation_range=10,\n","                                        zoom_range=0.1,\n","                                        horizontal_flip=True,\n","                                        vertical_flip=True,\n","                                        fill_mode='constant',\n","                                        cval=0,\n","                                        validation_split = 0.3,\n","                                        rescale=1./255)\n","else: #rescale only the image\n","     train_data_gen = ImageDataGenerator(rescale = 1./255, validation_split = 0.3)                                       \n","\n","#rescale only on validation dataset and test dataset\n","valid_data_gen = ImageDataGenerator(rescale = 1./255)\n","\n","test_data_gen = ImageDataGenerator(rescale = 1./255)\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"WLW6wdWvtV3g","executionInfo":{"status":"ok","timestamp":1605711742530,"user_tz":-60,"elapsed":29376,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["#width and height of imgaes\n","img_w = 256\n","img_h = 256\n","\n","num_classes = 3\n","\n","classes = [\"NO PERSON\", \"ALL THE PEOPLE\", \"SOMEONE\"]\n","\n","bs = 32 #batch size"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"uAU_S-XItV3g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605711783357,"user_tz":-60,"elapsed":70153,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}},"outputId":"8441bed5-a6e1-40e4-d21f-27b42bbb08c6"},"source":["from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","#Loading data \n","import json \n","\n","#setting dirs\n","dataset_dir = os.path.join('/content/drive/My Drive/PoliMi/1-ANN_DL/LAB/AN2DL-homeworks', \"MaskDataset\")\n","training_dir = os.path.join(dataset_dir, \"training\")\n","validation_dir = training_dir\n","\n","\n","#reading json file\n","with open(os.path.join(dataset_dir,\"train_gt.json\")) as f:\n","  dic = json.load(f)\n","\n","\n","dataframe = pandas.DataFrame(dic.items())\n","\n","dataframe.rename(columns = {0:'filename', 1:'class'}, inplace = True)\n","\n","dataframe[\"class\"] = dataframe[\"class\"].astype(str)\n","\n","train_gen = train_data_gen.flow_from_dataframe(dataframe,\n","                                               training_dir,\n","                                               batch_size=bs,\n","                                               target_size=(img_h, img_w),\n","                                               class_mode='categorical',\n","                                               shuffle=True,\n","                                               seed=SEED)\n","\n","valid_gen = valid_data_gen.flow_from_dataframe(dataframe,\n","                                               training_dir,\n","                                               batch_size=bs,\n","                                               target_size=(img_h, img_w),\n","                                               class_mode='categorical',\n","                                               shuffle=True,\n","                                               seed=SEED)                                                                                                                                                                                     "],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 30 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  .format(n_invalid, x_col)\n"],"name":"stderr"},{"output_type":"stream","text":["Found 5584 validated image filenames belonging to 3 classes.\n","Found 5584 validated image filenames belonging to 3 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 30 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n","  .format(n_invalid, x_col)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ouqBB0imtV3h","executionInfo":{"status":"ok","timestamp":1605711788427,"user_tz":-60,"elapsed":75062,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["#Creating Dataset objects\n","\n","\n","train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n","\n","train_dataset = train_dataset.repeat()\n","\n","\n","valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n","\n","valid_dataset = valid_dataset.repeat()     \n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNRpCxwGtV3h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605711789232,"user_tz":-60,"elapsed":75763,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}},"outputId":"5c42640d-5b37-48a4-8d8a-353522847b49"},"source":["# Architecture: Features extraction -> Classifier\n","\n","model = tf.keras.Sequential()\n","\n","transfer_learning = True\n","\n","if transfer_learning:\n","    # Load VGG16 Model\n","\n","    vgg = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))\n","    # Create Model\n","    # ------------\n","\n","    finetuning = True\n","\n","    if finetuning:\n","        freeze_until = 15 # layer from which we want to fine-tune\n","        \n","        for layer in vgg.layers[:freeze_until]:\n","            layer.trainable = False\n","    else:\n","        vgg.trainable = False\n","        \n","    model.add(vgg)\n","\n","else:\n","    #Creating a CNN from scratch\n","    start_f = 8\n","    depth = 5\n","\n","    \n","\n","    # Features extraction\n","    for i in range(depth):\n","\n","        if i == 0:\n","            input_shape = [img_h, img_w, 3]\n","        else:\n","            input_shape=[None]\n","\n","        # Conv block: Conv2D -> Activation -> Pooling\n","        model.add(tf.keras.layers.Conv2D(filters=start_f, \n","                                        kernel_size=(3, 3),\n","                                        strides=(1, 1),\n","                                        padding='same',\n","                                        input_shape=input_shape))\n","        model.add(tf.keras.layers.ReLU())\n","        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","\n","        start_f *= 2\n","    \n","# Classifier\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n","if(transfer_learning == False):\n","    model.add(tf.keras.layers.Dropout(0.5))\n","model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SbWa8tHKtV3h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605711790575,"user_tz":-60,"elapsed":613,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}},"outputId":"ce9e2c73-ebba-4c91-ecd3-530e74b99c96"},"source":["model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","vgg16 (Functional)           (None, 8, 8, 512)         14714688  \n","_________________________________________________________________\n","flatten (Flatten)            (None, 32768)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               16777728  \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3)                 1539      \n","=================================================================\n","Total params: 31,493,955\n","Trainable params: 23,858,691\n","Non-trainable params: 7,635,264\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OPS1_0_qtV3h","executionInfo":{"status":"ok","timestamp":1605711790578,"user_tz":-60,"elapsed":572,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["# Load the model\n","load_model = False\n","if load_model:\n","    latest = tf.train.latest_checkpoint(os.path.join(\"C:\\\\Users\\\\Giovanni\\\\Desktop\\\\UniversitÃ \\\\Magistrale\\\\ANN\\\\AN2DL-homeworks\\\\image-classification\\\\classification_experiments\\\\CNN_Nov12_19-13-43\\\\ckpts\", \"\"))\n","    model.load_weights(latest, by_name=False)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"vT_wpKyNtV3h","executionInfo":{"status":"ok","timestamp":1605711790579,"user_tz":-60,"elapsed":563,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["# Optimization params\n","# -------------------\n","\n","# Loss\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","\n","# learning rate\n","lr = 1e-4\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","# -------------------\n","\n","# Validation metrics\n","# ------------------\n","\n","metrics = ['accuracy']\n","# ------------------\n","\n","# Compile Model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"bA1C1HyctV3h","executionInfo":{"status":"ok","timestamp":1605711790892,"user_tz":-60,"elapsed":835,"user":{"displayName":"Matteo Sacco","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4t-2NKSz5HYbjIWzAFKCLH26R97WZMaAzrbuZVA=s64","userId":"08396135464959504472"}}},"source":["from datetime import datetime\n","\n","\n","\n","exps_dir = os.path.join(cwd, 'classification_experiments')\n","if not os.path.exists(exps_dir):\n","    os.makedirs(exps_dir)\n","\n","now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","model_name = 'CNN'\n","\n","exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","if not os.path.exists(exp_dir):\n","    os.makedirs(exp_dir)\n","    \n","callbacks = []\n","\n","# Model checkpoint\n","# ----------------\n","ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","if not os.path.exists(ckpt_dir):\n","    os.makedirs(ckpt_dir)\n","\n","ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n","                                                   save_weights_only=True)  # False to save the model directly\n","callbacks.append(ckpt_callback)\n","\n","# Visualize Learning on Tensorboard\n","# ---------------------------------\n","tb_dir = os.path.join(exp_dir, 'tb_logs')\n","if not os.path.exists(tb_dir):\n","    os.makedirs(tb_dir)\n","    \n","# By default shows losses and metrics for both training and validation\n","tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                             profile_batch=0,\n","                                             histogram_freq=1)  # if 1 shows weights histograms\n","callbacks.append(tb_callback)\n","\n","# Early Stopping\n","# --------------\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True )\n","    callbacks.append(es_callback)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_AA2DVwtV3h","colab":{"base_uri":"https://localhost:8080/"},"outputId":"14ddadbe-0f84-4ec9-e581-315ca42f5462"},"source":["model.fit(x=train_dataset,\n","          epochs=30,  #### set repeat in training dataset\n","          steps_per_epoch=len(train_gen),\n","          validation_data=valid_dataset,\n","          validation_steps=len(valid_gen), \n","          callbacks=callbacks)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","129/175 [=====================>........] - ETA: 6:14 - loss: 0.9483 - accuracy: 0.5373"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nCzQhLF6tV3h"},"source":["#check that is all ok\n","\n","#iterator = iter(valid_dataset)\n","\n","\n","\n","#from PIL import Image\n","\n","#for i in range(10):\n","#    sample, target = next(iterator)\n","#    sample_ = sample[0, ...]\n","\n","#    img = Image.fromarray(np.uint8(np.array(sample_)*255.))\n","#    img = img.resize([img_w,img_h])\n","#    img_array = np.array(img)\n","#    img_array = np.expand_dims(img_array, 0) \n","#    img_array = tf.cast(img_array, tf.float32) / 255.\n","#    prediction = model.predict(img_array)\n","#    img\n","#    print(\"Predicted:\"+classes[np.argmax(prediction)])\n","#    print(\"Original:\" +classes[tf.argmax(target[0], axis=0)])\n","\n","#sample_\n","#class_names[tf.argmax(target[0], axis=0)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZjVxesutV3h"},"source":["# Test Dataset \n","# Useful if you want to see images with predictions  \n","\n","#from PIL import Image\n","#image_filenames = next(os.walk('MaskDataset/test'))[2]\n","\n","#results = {}\n","#for image_name in image_filenames:\n","#   img = Image.open('MaskDataset/test/'+image_name).convert('RGB')\n","#   img = img.resize((img_w,img_h))\n","#   img_array = np.array(img)\n","#   img_array = np.expand_dims(img_array, 0) \n","#   img_array = tf.cast(img_array, tf.float32) / 255.\n","#   prediction = model.predict(img_array)\n","#   img\n","#   classes[np.argmax(prediction)]\n","   \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vzhOuUqRtV3h"},"source":["#Creating CSV\n","\n","import os\n","from datetime import datetime\n","from PIL import Image\n","\n","def create_csv(results, results_dir='./'):\n","\n","    csv_fname = 'results_'\n","    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n","\n","    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n","\n","        f.write('Id,Category\\n')\n","\n","        for key, value in results.items():\n","            f.write(key + ',' + str(value) + '\\n')\n","\n","\n","image_filenames = next(os.walk('MaskDataset/test'))[2]\n","\n","results = {}\n","for image_name in image_filenames:\n","   img = Image.open('MaskDataset/test/'+image_name).convert('RGB')\n","   img = img.resize((img_w,img_h))\n","   img_array = np.array(img)\n","   img_array = np.expand_dims(img_array, 0) \n","   img_array = tf.cast(img_array, tf.float32) / 255.\n","   prediction = model.predict(img_array)\n","   results[image_name] = np.argmax(prediction)\n","\n","create_csv(results)            "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4fXkFwZwtV3h"},"source":[""],"execution_count":null,"outputs":[]}]}